{
	"debugpy for pytorch": {
		"prefix": "debugpy-pytorch-ink",
		"body": [
			"debug = True",
			"",
			"if debug:",
			"    # improve torch tensor printing",
			"    import torch",
			"    def custom_repr(self):",
			"        return f'{{Tensor:{tuple(self.shape)}}} {original_repr(self)}'",
			"    original_repr = torch.Tensor.__repr__",
			"    torch.Tensor.__repr__ = custom_repr",
			"",
			"    # debug with debugpy",
			"    import debugpy",
			"    # Listen on a specific port (choose any available port, e.g., 61074)",
			"    debugpy.listen((\"0.0.0.0\", 61074))",
			"    print(\"Waiting for debugger to attach...\")",
			"    # Optional: Wait for the debugger to attach before continuing execution",
			"    debugpy.wait_for_client()"
		],
		"description": "Sets up debugpy and custom tensor printing for PyTorch",
    "scope": "python"
	},
  "print pytorch and cuda info":{
    "prefix": "pytorch-cuda-info",
    "body": [
        "import torch",
        "print('Pytorch version\t:', torch.__version__)",
        "print('CUDA version\t:', torch.version.cuda)",
        "print('GPU\t\t:',torch.cuda.get_device_name())",
        "",
        "if torch.cuda.is_available():",
        "    # Get the properties of the first GPU (GPU 0)",
        "    device_properties = torch.cuda.get_device_properties(0)",
        "    compute_capability = device_properties.major, device_properties.minor",
        "    print('device properties: \n', device_properties)",
        "    print(f'GPU Compute Capability: {compute_capability[0]}.{compute_capability[1]}')",
        "else:",
        "    print('CUDA is not available on this system.')",
    ],
    "description": "print pytorch build info",
    "scope": "python"
  }
}
